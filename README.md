# Metric-Based In-Context Learning: A Case Study in Text Simplification

The folders of this repository are organized as follows:

* BERTPrec - BERTPrec selected examples
* CR - Compression Ratio selected examples
* EASSE Reports - This includes the original EASSE reports with information on the BLEU, SARI, and FKGL scores of each experiment. They can be replicated using the original EASSE code linked here: EASSE
* FestAbility - SOTA results replicated on the FestAbility dataset during task-transfer experiments
* KATE-GPT - We tried using KATE-GPT to select examples, and the folder includes our results and code utilizing that method.
* Ordering Examples - We ordered the examples selected by scores in different ways, and this folder includes those results.
* Random Baseline - Results of our random baseline
* SARI - SARI selected examples
* Zeroshot - Model's zero-shot results

Each individual folder has its own README with more information on the files and folders inside. 

If you have any questions, please feel free to email subhavee2@gmail.com. Thank you!
